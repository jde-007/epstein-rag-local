import json
import shutil
from pathlib import Path
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

CHROMA_DIR = "chroma_db"

# --------------------------------------------------
# Reset Chroma DB
# --------------------------------------------------
if Path(CHROMA_DIR).exists():
    print("ğŸ§¹ Removing existing Chroma DB...")
    shutil.rmtree(CHROMA_DIR)

# --------------------------------------------------
# Load chunks
# --------------------------------------------------
print("ğŸ“‚ Loading chunks...")

with open("data/chunks.json", "r", encoding="utf-8") as f:
    chunks = json.load(f)

total_chunks = len(chunks)
print(f"âœ… Loaded {total_chunks} chunks")

# --------------------------------------------------
# Load embedding model
# --------------------------------------------------
print("ğŸ§  Loading embedding model...")

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

print("âœ… Embedding model ready")

# --------------------------------------------------
# Create Chroma DB
# --------------------------------------------------
print("ğŸ“¦ Initializing Chroma vector store...")

db = Chroma(
    collection_name="epstein",
    persist_directory=CHROMA_DIR,
    embedding_function=embeddings
)

# --------------------------------------------------
# Embed in batches
# --------------------------------------------------
BATCH = 1000
print(f"ğŸš€ Starting embedding in batches of {BATCH}")

for i in range(0, total_chunks, BATCH):
    end = min(i + BATCH, total_chunks)
    print(f"ğŸ”¹ Embedding chunks {i + 1} â†’ {end} / {total_chunks}")

    db.add_texts(
        texts=[c["text"] for c in chunks[i:end]],
        metadatas=[c["metadata"] for c in chunks[i:end]]
    )

print("ğŸ‰ Chroma embedding complete")
print("ğŸ“ Vector DB saved at:", CHROMA_DIR)
